# STOCKS in Motion: Building a Real-Time Pipeline with Kafka and MLops

Welcome to the GitHub repository for the "Stocks in Motion" project! This is an end-to-end data engineering project that demonstrates how to build a real-time stock market data processing engine using Kafka and other tools and cloud services. In this project, I have used different technologies such as Python, Amazon Web Services (AWS), Apache Kafka, Glue, Athena, and SQL to create a robust and scalable data pipeline.

## Project Overview

The goal of this project is to create a real-time pipeline that can process stock market data as soon as it becomes available. The pipeline is designed to ingest data from a variety of sources and transform it into a format that can be easily analyzed and visualized. To achieve this, I have used Apache Kafka as the messaging system and AWS services such as S3, Athena, Glue Crawler, Glue Catalog, and EC2 for storage, processing, and analysis.

To help you better understand the flow of the project, I have created an architecture diagram on Canva, which you can find here ![architecture 1](https://user-images.githubusercontent.com/71492927/227791912-57cce552-dd85-4f08-8ec3-c18d6db560ab.png)
![architecture 2](https://user-images.githubusercontent.com/71492927/227792116-833ff4aa-6843-4271-a32a-5e5af0387a29.png)
. Please note that the diagram is not comprehensive, and there may be many small details that are not included. Additionally, during the course of this project, I encountered and resolved many errors that are not included in the diagram. Nonetheless, it should give you a good idea of how the different components of the pipeline fit together.

## Technology Used

The project is implemented using the following technologies:

- Programming Language: Python
- Amazon Web Services (AWS)
- S3 (Simple Storage Service)
- Athena
- Glue Crawler
- Glue Catalog
- EC2
- Apache Kafka

## Dataset

To keep things realistic, I have used a stock market dataset as the source of data for this project. However, any dataset can be used as input to the pipeline. The dataset used in this project can be found in the [data](https://chat.openai.com/data) directory.

## Code

The code for this project is provided in the [code](https://chat.openai.com/code) directory. The code is organized into different modules that perform specific tasks such as data ingestion, data transformation, and data visualization.

## Case Study

If you are interested in learning how Spotify utilizes Apache Kafka for real-time data processing and personalized recommendations, please check out my small case study, which you can find [here](https://www.linkedin.com/feed/update/urn:li:share:7037686827721383936/).

## Project Walkthrough

Finally, I have created a video walkthrough of the project, which you can find [here](https://www.youtube.com/watch?v=XXXXXXXXXXX). This walkthrough will take you through the different components of the pipeline and provide an overview of how they work together.

Thank you for your interest in the "Stocks in Motion" project! If you have any questions or comments, please feel free to reach out to me.
